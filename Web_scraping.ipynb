{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "id": "86LTYvGJXg_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "cc-PyfFlBW4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyMuPDF"
      ],
      "metadata": {
        "id": "n3PKReM_qREg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tabula-py"
      ],
      "metadata": {
        "id": "VShvA1P_lkMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer"
      ],
      "metadata": {
        "id": "5aX0ZZFekxwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import io"
      ],
      "metadata": {
        "id": "ZPBCF3uwFoqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR0VRhGbXNWS"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import requests library\n",
        "import requests\n",
        "#the website URL\n",
        "url_link = \"http://www.zionsville-in.gov/Archive.aspx?AMID=68&Type=&ADID=\"\n",
        "result = requests.get(url_link).text\n",
        "doc = BeautifulSoup(result, \"html.parser\")\n",
        "\n",
        "print(doc.prettify())\n"
      ],
      "metadata": {
        "id": "alkE96ElZCwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def info(pdf_path):\n",
        " \n",
        "    # used get method to get the pdf file\n",
        "    response = requests.get(pdf_path)\n",
        " \n",
        "    # response.content generate binary code for\n",
        "    # string function\n",
        "    with io.BytesIO(response.content) as f:\n",
        " \n",
        "        # initialized the pdf\n",
        "        pdf = PdfFileReader(f)\n",
        " \n",
        "        # all info about pdf\n",
        "        information = pdf.getDocumentInfo()\n",
        " \n",
        "    txt = f\"\"\"\n",
        "    Information about {pdf_path}:\n",
        "     \n",
        "    Author: {information.author}\n",
        "    Creator: {information.creator}\n",
        "    Producer: {information.producer}\n",
        "    Subject: {information.subject}\n",
        "    Title: {information.title}\n",
        "    \"\"\"\n",
        "    print(txt)\n",
        "     \n",
        "    return information"
      ],
      "metadata": {
        "id": "TRm-p4OrNYs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# created an empty list for putting the pdfs\n",
        "list_of_pdf = set()\n",
        " \n",
        "# accessed the first p tag in the html\n",
        "l = doc.find('p')\n",
        " \n",
        "# accessed all the anchors tag from given p tag\n",
        "p = l.find_all('a')\n",
        " \n",
        "# iterate through p for getting all the href links\n",
        "for link in p:\n",
        "     \n",
        "    # original html links\n",
        "    print(\"links: \", link.get('href'))\n",
        "     \n",
        "    # converting the extension from .html to .pdf\n",
        "    pdf_link = (link.get('href')[:-5]) + \".pdf\"\n",
        "     \n",
        "    # converted to .pdf\n",
        "    print(\"converted pdf links: \", 'http:/'+pdf_link)\n",
        "    print(\"\\n\")\n",
        "     \n",
        "    # added all the pdf links to set\n",
        "    list_of_pdf.add(pdf_link)"
      ],
      "metadata": {
        "id": "K8XO50f8OBww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list_of_pdf:\n",
        "    info(i)"
      ],
      "metadata": {
        "id": "-baO9NxFSCyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tabula\n",
        "\n",
        "pdf_path = \"/content/Resolution 2023-06 - Regarding the Appropriation of Additional Funds (Police Vehicles).pdf\"\n",
        "\n",
        "dfs = tabula.read_pdf(pdf_path, pages = '2')\n",
        "print(dfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZRXbMOfl6lx",
        "outputId": "e2fb5d91-0517-4abd-87a4-603ccb0f865d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PIL\n",
        "!pip install pytesseract\n",
        "!pip install pdf2image\n"
      ],
      "metadata": {
        "id": "OC9SW9jw91bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "id": "QJwXAibnBvPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libs\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "import Image\n",
        "import cv2\n",
        "import pytesseract\n",
        "import os\n",
        "import numpy as np\n",
        "from pdf2image import convert_from_bytes\n",
        "\n",
        "# Some help functions \n",
        "def get_conf(page_gray):\n",
        "    '''return a average confidence value of OCR result '''\n",
        "    df = pytesseract.image_to_data(page_gray,output_type='data.frame')\n",
        "    df.drop(df[df.conf==-1].index.values,inplace=True)\n",
        "    df.reset_index()\n",
        "    return df.conf.mean()\n",
        "  \n",
        "def deskew(image):\n",
        "    '''deskew the image'''\n",
        "    gray = cv2.bitwise_not(image)\n",
        "    temp_arr = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    coords = np.column_stack(np.where(temp_arr > 0))\n",
        "    angle = cv2.minAreaRect(coords)[-1]\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = -angle\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "    return rotated\n",
        "  \n",
        "'''\n",
        "Main part of OCR:\n",
        "pages_df: save eextracted text for each pdf file, index by page\n",
        "OCR_dic : dict for saving df of each pdf, filename is the key\n",
        "'''\n",
        " \n",
        "OCR_dic={} \n",
        "for file in list_of_pdf:\n",
        "    # convert pdf into image\n",
        "    pdf_file = convert_from_bytes(open(os.path.join(PATH,file), 'rb').read())\n",
        "    # create a df to save each pdf's text\n",
        "    pages_df = pd.DataFrame(columns=['conf','text'])\n",
        "    for (i,page) in enumerate(pdf_file) :\n",
        "        try:\n",
        "            # transfer image of pdf_file into array\n",
        "            page_arr = np.asarray(page)\n",
        "            # transfer into grayscale\n",
        "            page_arr_gray = cv2.cvtColor(page_arr,cv2.COLOR_BGR2GRAY)\n",
        "            # deskew the page\n",
        "            page_deskew = deskew(page_arr_gray)\n",
        "            # cal confidence value\n",
        "            page_conf = get_conf(page_deskew)\n",
        "            # extract string \n",
        "            pages_df = pages_df.append({'conf': page_conf,'text': pytesseract.image_to_string(page_deskew)}, ignore_index=True)\n",
        "        except:\n",
        "            # if can't extract then give some notes into df\n",
        "            pages_df = pages_df.append({'conf': -1,'text': 'N/A'}, ignore_index=True)\n",
        "            continue\n",
        "    # save df into a dict with filename as key        \n",
        "    OCR_dic[file]=pages_df\n",
        "    print('{} is done'.format(file))"
      ],
      "metadata": {
        "id": "ahz6cg5PG5E0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}